#!/usr/bin/env python3
"""
AGGREGATE JSON - –ê–≥—Ä–µ–≥–∞—Ü–∏—è –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –≤ JSON
–ó–∞–ø—É—Å–∫: python aggregate_json.py [–ø–∞–ø–∫–∞_—Å_pdf]

–°–æ–∑–¥–∞–µ—Ç –µ–¥–∏–Ω—ã–π JSON —Ñ–∞–π–ª —Å–æ –≤—Å–µ–º–∏ –¥–∞–Ω–Ω—ã–º–∏.
"""

import json
import sqlite3
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict

# –ü—É—Ç–∏
DATA_DIR = Path(__file__).parent / "data"
OUTPUT_FILE = DATA_DIR / "complete_knowledge_base.json"

def get_pdf_folder():
    """–ü–æ–ª—É—á–∏—Ç—å –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ —Å PDF"""
    print("\n" + "="*60)
    print("–í–´–ë–û–† –ü–ê–ü–ö–ò –° PDF (–¥–ª—è OCR)")
    print("="*60)
    print()
    print("–ï—Å–ª–∏ —É –≤–∞—Å –µ—Å—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ PDF, —É–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –Ω–∏–º.")
    print("–ï—Å–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –ø—É—Å—Ç—ã–º, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ —Ç–æ–ª—å–∫–æ –±–∞–∑–∞ —Ñ–æ—Ä–º—É–ª.")
    print()
    print("–ü—Ä–∏–º–µ—Ä—ã –ø—É—Ç–µ–π:")
    print("  Windows: C:/Users/–ò–º—è/Desktop/–ø–¥—Ñ")
    print("  Linux/Mac: /home/–∏–º—è/documents/pdfs")
    print()
    
    default_path = "C:/Users/New/Desktop/–ø–¥—Ñ"
    user_input = input(f"–ü—É—Ç—å –∫ PDF (Enter –¥–ª—è –ø—Ä–æ–ø—É—Å–∫–∞) [{default_path}]: ").strip()
    
    if not user_input:
        print("\n‚ö† –ü—Ä–æ–ø—É—Å–∫–∞–µ–º PDF, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ JSON –¥–∞–Ω–Ω—ã–µ")
        return None
    
    folder_path = Path(user_input).expanduser().resolve()
    
    if not folder_path.exists():
        print(f"\n‚ùå –ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
        retry = input("–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å–Ω–æ–≤–∞? (y/n): ").strip().lower()
        if retry in ['y', 'yes', '–¥', '–¥–∞']:
            return get_pdf_folder()
        else:
            print("‚ö† –ü—Ä–æ–ø—É—Å–∫–∞–µ–º PDF")
            return None
    
    pdf_files = list(folder_path.glob("*.pdf"))
    print(f"\n‚úì –ü–∞–ø–∫–∞ –Ω–∞–π–¥–µ–Ω–∞: {folder_path}")
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ PDF: {len(pdf_files)}")
    
    return folder_path

def load_json(filename):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å JSON —Ñ–∞–π–ª"""
    filepath = DATA_DIR / filename
    if filepath.exists():
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def load_from_sqlite():
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ SQLite"""
    db_path = DATA_DIR / "knowledge_base.db"
    documents = []
    
    if not db_path.exists():
        print("‚ö† SQLite –±–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return documents
    
    try:
        conn = sqlite3.connect(str(db_path))
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id, filename, title, doc_type, categories, content, content_length
            FROM documents
        ''')
        
        for row in cursor.fetchall():
            doc = {
                'id': row['id'],
                'filename': row['filename'],
                'title': row['title'],
                'type': row['doc_type'],
                'categories': json.loads(row['categories']) if row['categories'] else [],
                'content': row['content'],
                'content_length': row['content_length']
            }
            documents.append(doc)
        
        conn.close()
        print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ SQLite")
        
    except Exception as e:
        print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ SQLite: {e}")
    
    return documents

def load_from_txt(pdf_folder: Optional[Path] = None):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ TXT —Ñ–∞–π–ª–æ–≤ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ OCR)"""
    documents = []
    
    if not pdf_folder or not pdf_folder.exists():
        print("‚ö† –ü–∞–ø–∫–∞ —Å PDF –Ω–µ —É–∫–∞–∑–∞–Ω–∞ –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º .txt")
        return documents
    
    txt_dir = pdf_folder / "ocr_results"
    if not txt_dir.exists():
        txt_dir = pdf_folder
    
    txt_files = list(txt_dir.glob("*.txt"))
    
    if not txt_files:
        print("‚ö† TXT —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return documents
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(txt_files)} TXT —Ñ–∞–π–ª–æ–≤")
    
    for i, txt_file in enumerate(txt_files, 1):
        try:
            with open(txt_file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            filename = txt_file.stem + ".pdf"
            
            doc = {
                'id': i,
                'filename': filename,
                'title': txt_file.stem,
                'type': 'pdf',
                'categories': [],
                'content': content,
                'content_length': len(content)
            }
            documents.append(doc)
            
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {txt_file.name}: {e}")
    
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ TXT")
    return documents

def load_from_html(pdf_folder: Optional[Path] = None):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML —Ñ–∞–π–ª–æ–≤"""
    documents = []
    
    if not pdf_folder or not pdf_folder.exists():
        return documents
    
    html_files = list(pdf_folder.glob("*.html")) + list(pdf_folder.glob("*.htm"))
    
    if not html_files:
        return documents
    
    print(f"‚úì –ù–∞–π–¥–µ–Ω–æ {len(html_files)} HTML —Ñ–∞–π–ª–æ–≤")
    
    try:
        from bs4 import BeautifulSoup
    except ImportError:
        print("‚ö† –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ beautifulsoup4 –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ HTML: pip install beautifulsoup4")
        return documents
    
    for i, html_file in enumerate(html_files, 1):
        try:
            with open(html_file, 'r', encoding='utf-8', errors='ignore') as f:
                soup = BeautifulSoup(f.read(), 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ HTML
            text = soup.get_text(separator='\n', strip=True)
            
            doc = {
                'id': 10000 + i,  # ID > 10000 –¥–ª—è HTML
                'filename': html_file.name,
                'title': html_file.stem,
                'type': 'html',
                'categories': [],
                'content': text,
                'content_length': len(text)
            }
            documents.append(doc)
            
        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {html_file.name}: {e}")
    
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ HTML")
    return documents

def save_to_sqlite(documents: List[Dict]):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ SQLite"""
    if not documents:
        return
    
    db_path = DATA_DIR / "knowledge_base.db"
    
    try:
        conn = sqlite3.connect(str(db_path))
        cursor = conn.cursor()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –Ω–µ—Ç
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS documents (
                id INTEGER PRIMARY KEY,
                filename TEXT,
                title TEXT,
                doc_type TEXT,
                categories TEXT,
                content TEXT,
                content_length INTEGER
            )
        ''')
        
        for doc in documents:
            cursor.execute('''
                INSERT OR REPLACE INTO documents 
                (filename, title, doc_type, categories, content, content_length)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                doc.get('filename', ''),
                doc.get('title', ''),
                doc.get('type', 'pdf'),
                json.dumps(doc.get('categories', [])),
                doc.get('content', ''),
                doc.get('content_length', 0)
            ))
        
        conn.commit()
        conn.close()
        print(f"‚úì –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ SQLite")
        
    except Exception as e:
        print(f"‚ö† –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ SQLite: {e}")

def check_ocr_available():
    """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å OCR"""
    try:
        import pytesseract
        pytesseract.get_tesseract_version()
        return True
    except:
        return False

def run_ocr_if_needed(pdf_folder):
    """–°–æ–∑–¥–∞—Ç—å SQLite –±–∞–∑—É –∏–∑ PDF"""
    if not pdf_folder:
        return False
    
    db_path = DATA_DIR / "knowledge_base.db"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —É–∂–µ –±–∞–∑–∞
    if db_path.exists():
        print(f"\n‚ö† –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {db_path}")
        choice = input("–ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å? (y/n): ").strip().lower()
        if choice not in ['y', 'yes', '–¥', '–¥–∞']:
            print("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –±–∞–∑—É")
            return True
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º OCR
    if not check_ocr_available():
        print("\n‚ùå OCR –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω!")
        print("–î–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è PDF —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ:")
        print("  1. Tesseract-OCR —Å —Ä—É—Å—Å–∫–∏–º —è–∑—ã–∫–æ–º")
        print("  2. Python –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: pip install pytesseract pdf2image pillow")
        print("\n–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –±–µ–∑ OCR? (–±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã —Ç–æ–ª—å–∫–æ JSON –¥–∞–Ω–Ω—ã–µ)")
        choice = input("(y/n): ").strip().lower()
        if choice not in ['y', 'yes', '–¥', '–¥–∞']:
            print("–û—Ç–º–µ–Ω–µ–Ω–æ")
            return False
        return True
    
    # –°–æ–∑–¥–∞–µ–º SQLite –±–∞–∑—É –∏–∑ PDF
    print("\n" + "="*60)
    print("–°–û–ó–î–ê–ù–ò–ï –ë–ê–ó–´ –î–ê–ù–ù–´–• –ò–ó PDF")
    print("="*60)
    
    try:
        import subprocess
        result = subprocess.run(
            [sys.executable, "processor/build_full_database.py", str(pdf_folder)],
            cwd=Path(__file__).parent
        )
        return result.returncode == 0
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False

def aggregate():
    """–°–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—É—é –∞–≥—Ä–µ–≥–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö"""
    print("=" * 60)
    print("–ê–ì–†–ï–ì–ê–¶–ò–Ø –î–ê–ù–ù–´–• –í JSON")
    print("=" * 60)
    print()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–∞–ø–∫—É —Å PDF
    pdf_folder = None
    if len(sys.argv) > 1:
        # –ü—É—Ç—å –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
        pdf_folder = Path(sys.argv[1])
        print(f"‚úì –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ø–∫—É: {pdf_folder}")
    else:
        # –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤—ã–±–æ—Ä
        pdf_folder = get_pdf_folder()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º OCR –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if pdf_folder:
        run_ocr_if_needed(pdf_folder)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print("\n" + "="*60)
    print("–ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–•")
    print("="*60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ SQLite
    documents = load_from_sqlite()
    
    # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º TXT —Ñ–∞–π–ª—ã –∏ –¥–æ–±–∞–≤–ª—è–µ–º –≤ –±–∞–∑—É
    if pdf_folder:
        txt_documents = load_from_txt(pdf_folder)
        if txt_documents:
            save_to_sqlite(txt_documents)
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏
            existing_ids = {doc['id'] for doc in documents}
            for doc in txt_documents:
                if doc['id'] not in existing_ids:
                    documents.append(doc)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HTML —Ñ–∞–π–ª—ã
        html_documents = load_from_html(pdf_folder)
        if html_documents:
            save_to_sqlite(html_documents)
            existing_ids = {doc['id'] for doc in documents}
            for doc in html_documents:
                if doc['id'] not in existing_ids:
                    documents.append(doc)
    
    data = {
        'metadata': {
            'created': datetime.now().isoformat(),
            'version': '2.0',
            'source': 'Ancestral Numerology Knowledge Base'
        },
        'formulas': load_json('formulas.json'),
        'practices': load_json('practices.json'),
        'number_meanings': load_json('number_meanings.json'),
        'algorithms': load_json('algorithms.json'),
        'documents': documents
    }
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    stats = {
        'formulas': len(data['formulas']),
        'practices': len(data['practices']),
        'number_meanings': len(data['number_meanings']),
        'algorithms': len(data['algorithms']),
        'documents': len(data['documents'])
    }
    
    print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  –§–æ—Ä–º—É–ª: {stats['formulas']}")
    print(f"  –ü—Ä–∞–∫—Ç–∏–∫: {stats['practices']}")
    print(f"  –ó–Ω–∞—á–µ–Ω–∏–π —á–∏—Å–µ–ª: {stats['number_meanings']}")
    print(f"  –ê–ª–≥–æ—Ä–∏—Ç–º–æ–≤: {stats['algorithms']}")
    print(f"  –î–æ–∫—É–º–µ–Ω—Ç–æ–≤ PDF: {stats['documents']}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤: {OUTPUT_FILE}")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    file_size = OUTPUT_FILE.stat().st_size / 1024 / 1024
    print(f"‚úì –ì–æ—Ç–æ–≤–æ! –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size:.2f} MB")
    print()
    print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:")
    print(f"  with open('{OUTPUT_FILE.name}', 'r', encoding='utf-8') as f:")
    print("      data = json.load(f)")
    print("      formulas = data['formulas']")
    print("      practices = data['practices']")
    print("      documents = data['documents']")

if __name__ == '__main__':
    aggregate()
    input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –≤—ã—Ö–æ–¥–∞...")
